{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-21tlRxnfLW"
      },
      "source": [
        "# SNLP Assignment 1\n",
        "\n",
        "Name 1: <br/>\n",
        "Student id 1: <br/>\n",
        "Email 1: <br/>\n",
        "\n",
        "\n",
        "Name 2: <br/>\n",
        "Student id 2: <br/>\n",
        "Email 2: <br/> \n",
        "\n",
        "**Instructions:** Read each question carefully. <br/>\n",
        "Make sure you appropriately comment your code wherever required. Your final submission should contain the completed Notebook and the respective Python files for exercises 2, 3, and the bonus question (if you attempt it). There is no need to submit the data files. <br/>\n",
        "Upload the zipped folder in Teams. Make sure to click on \"Turn-in\" after your upload your submission, otherwise the assignment will not be considered as submitted. Only one member of the group should make the submisssion.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxs-Ck3mdL1m"
      },
      "source": [
        "## Exercise 1 (0 points)\n",
        "\n",
        "Please carefully read the instructions on how to use Jupyter Notebooks and how to hand in the assignments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o_hqMzc7qAH"
      },
      "source": [
        "## Exercise 2 (4 = 1+1+2 points)\n",
        "\n",
        "The **Mandelbrot distribution** is a power-law distribution over ranked data.\n",
        "\\begin{equation}\n",
        "f(r) \\propto \\frac{m}{(c+r)^B}\n",
        "\\end{equation}\n",
        "Here $r$ is the rank of the data point and $c$ and $B$ are the parameters that define the distribution. $m$ is a normalizing constant ensuring that the distribution is a true probability distribution. \n",
        "\n",
        "**Zipf's** law or rather the Zipfian distribution is a special case of the Mandelbrot distribution. It holds that the relative frequency of a word in a corpus is inversely proportional to its rank in the frequency table. \n",
        "\n",
        "1. Which values for $m$, $c$ yield the Zipfian distribution? Explain how you arrived at these values. Show the result in the form of a $\\LaTeX$ formula. What is a reasonable value for $B$? (1 Point)\n",
        "\n",
        "Ans: Any value of m would hold Zipfian law as it is only a shift of the curve up and down acting as a normalizer. c should have value of 0. To hold the propert \"relative frequency of a word in a corpus inversly proportional to its rank\", value of B(scope of the plot) should be 1.\n",
        "\\begin{equation}\n",
        "f(r) \\propto \\frac{m}{(0+r)^1} \\\\\n",
        "f(r) \\propto \\frac{m}{r}\n",
        "\\end{equation}\n",
        "\n",
        "2. Look again at Chapter 2, Slide 16. Why do the parameters of the distribution ($m$, $c$, $B$) differ in practice, i. e. for a real language, whether natural or artificial, from those obtained in 1.? (1 Point)\n",
        "\n",
        "Zipfâ€™s  law  predicts  that  the double log  graph of frequency vs rank should  be  a  straight  line  with  slope  -1 while Mandelbrot came up with the parameters which says the zipfian distribution is not always correct for all text corpus (not for high rank and low rank words) and hence tuning these parameter we can find the fit for words in a corpus. Since, these parameters depends on the corpus and we tune these to find more general fit and relation ebtween rank and frequency, it would be different for different corpus.\n",
        "\n",
        "3. The so-called stick-breaking process is a notion of the [Dirichlet process](https://en.wikipedia.org/wiki/Dirichlet_process#The_stick-breaking_process). (the following [blog post](https://medium.com/@albertoarrigoni/dirichlet-processes-917f376b02d2) gives a nice introduction into the Dirichlet process, you should at least read the part concerned with stick-breaking).\n",
        "The function `stick_breaking` in the code cell below draws a sample from a stick-breaking process with intensity $\\alpha$. \n",
        "  * Choose a suitable value of $\\alpha$ such that the distribution follows Zipf's law, and explain how $\\alpha$ affects the distribution. \n",
        "  * Sample 100 values from the distribution, and plot them on log scale along with the 'ideal' Zipfian distribution obtained in 1. You will have to adjust the exponent $B$ such that it matches the distribution. The plotting code should be added to and imported from `exercise_2.py`. If you make changes to the code block below, please comment on why it was necessary.\n",
        "  * Relate to your findings in 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giiP4QKjmfYa"
      },
      "source": [
        "from importlib import reload\n",
        "import exercise_2\n",
        "exercise_2 = reload(exercise_2)\n",
        "\n",
        "n = 100\n",
        "alpha = # TODO: choose alpha\n",
        "B = # TODO: choose B\n",
        "\n",
        "stick_lengths = exercise_2.stick_breaking(n, alpha)\n",
        "exercise_2.plot_stick_lengths(stick_lengths, alpha, B) #TODO: in exercise_2.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wO9uGvZ76RW"
      },
      "source": [
        "## Exercise 3 (6 = 3+0.5+1+0.5+1 points)\n",
        "\n",
        "The following cell executes the function `analysis` from the `exercise_3.py` file. You are given a tokenized input (list of words). \n",
        "\n",
        "1. Plot the frequencies against rank for the inputs (different languages) along with an 'ideal' curve according to the Zipf's law. Use the log-log scale. (3 points)\n",
        "\n",
        "Then, answer the following questions and elaborate:\n",
        "\n",
        "2. Does Zipf's law form an accurate prediction of your data? (0.5 point)\n",
        "3. What are the differences between the languages? What causes them? (1 point)\n",
        "4. In your plot, what causes the vertical gaps (\"steps\") for high-rank words  (rightmost)? (0.5 point)\n",
        "5. Zipf's law \"predicts\" the frequency of the n-th rank word. Compute the mean squared error of these predictions $\\big(\\frac{1}{n} \\sum (\\hat{y} - y)^2\\big)$, and output the value to 10 decimal digits. (1 point)\n",
        "\n",
        "Please extend `exercise_3.py`. Ideally the following cell remains unchanged and outputs your code. If you make changes, please comment on why it was necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QsrwdIsA2gJ"
      },
      "source": [
        "import tokenize\n",
        "from importlib import reload\n",
        "import exercise_3\n",
        "exercise_3 = reload(exercise_3)\n",
        "\n",
        "# run on English text\n",
        "with open(\"data/alice_in_wonderland.txt\", \"r\") as f:\n",
        "    exercise_3.analysis(\"English\", f.read().lower().split())\n",
        "\n",
        "# run on German text\n",
        "with open(\"data/alice_im_wunderland.txt\", \"r\") as f:\n",
        "    exercise_3.analysis(\"German\", f.read().lower().split())\n",
        "\n",
        "# run on PyTorch source\n",
        "with open(\"data/torch_activation.py\", \"r\") as f:\n",
        "    tokens = [\n",
        "        x.string\n",
        "        for x in tokenize.generate_tokens(f.readline)\n",
        "        if x.type not in {\n",
        "            tokenize.COMMENT, tokenize.STRING, tokenize.INDENT, tokenize.DEDENT, tokenize.NEWLINE\n",
        "        }\n",
        "    ]\n",
        "    exercise_3.analysis(\"Python\", tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyWwTwR0-bcq"
      },
      "source": [
        "# Bonus (1 point)\n",
        "\n",
        "Repeat exercise 3 but on the character level (as opposed to word level). Your analysis can be much shorter but comment on the differences between the languages. You have to, however, write your own loader similar to the one we provided. For this, you may create a file `bonus.py` and import your code from there in a similar fashion to the above questions."
      ]
    }
  ]
}